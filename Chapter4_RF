## CHAPTER 4 - The impact of social and environmental extremes on cholera time varying reproduction number in Nigeria
## INCIDENCE, R, COVARIATE SELECTION, RANDOM FOREST, NOWCASTING, TRAFFIC-LIGHT SYSTEM  

# Load packages 
# R
library(incidence)
library(EpiEstim) 
# Data manipulation
library(data.table)
library(plyr)
library(dplyr)
library(tibble)
# Date manipulation
library(zoo)
library(lubridate)
# Plotting
library(ggplot2)
library(magrittr)
# Model fitting
library(rsample) 
library(ranger)
library(caret) 


`````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````

## INCIDENCE & R BY STATE 

## Import my positive linelist data and just save the onset and state columns 
# Subset it 
df1 <- linelist_data[c(1,7)]
names(df1)[2]<-paste("date_of_onset")
onset18 <- subset(df1, date_of_onset <= "2018-12-31")
onset19 <- subset(df1, date_of_onset >= "2019-01-01")

# Save the states as a list 
# Run 18 and 19 separately because long gaps with no cases increases R uncertainty
adm_list <- (split(onset18, onset18$State))

# Subset out states with insufficient cases (40 case threshold) 
adm_list <- adm_list[sapply(adm_list, nrow)>=40] 
adm_data <- names(adm_list)

# Save serial interval and standard deviations for the sensitivity analysis 
mu1 <- 3
mu2 <- 5
mu3 <- 8
sd <- 8 

# Run function calculating Rt for each state over monthly sliding windows 
R_by_state <- function(adm_data) {
  i <- incidence(as.Date(adm_data$date_of_onset))
  t_start <- seq(2, nrow(i$count)-29) 
  t_end <- t_start + 29
  i <- data.frame(i$dates, i$counts)
  names(i)[1]<-paste("date")
  names(i)[2]<-paste("count")
  Rt <- estimate_Rt(i, estimation_family='epiestim', cumulative=TRUE, method = 'parametric_si', 
                    config = list(mean_si=mu2, std_si=sd, t_start = t_start, t_end = t_end))# change based on si
  i$t_start <- seq(nrow(i))
  Rt <- merge(i, Rt, by = "t_start", all.x = TRUE)
}
output_list18 <- lapply(adm_list, R_by_state)

## Do the same for 2019 then join them 
output_list <- Map(rbind, output_list18, output_list19)

# Merge to one data frame 
output_df <- ldply(output_list, data.frame)
output_df <- output_df[c(1,3,2,5,4,6,7,9,13)]
names(output_df)[1]<-paste("state")

# To remove the posterior CV warning message I ran states individually, so I could change t_start depending on their reported cases 
df1 <- df1[c(1,7)]
names(df1)[2]<-paste("date_of_onset")
df1$date_of_onset <- as.Date(df1$date_of_onset)
onset18 <- subset(df1, date_of_onset <= "2018-12-31")
onset19 <- subset(df1, date_of_onset >= "2019-01-01")
i18 <- onset18 %>% group_by(State, date_of_onset) %>% tally()
i19 <- onset19 %>% group_by(State, date_of_onset) %>% tally()
i18 <- i18 %>% group_by(State) %>% mutate(total = sum(n))
i19 <- i19 %>% group_by(State) %>% mutate(total = sum(n))
i18 <- subset(i18, total >= 40)
i19 <- subset(i19, total >= 40)

list2env(split(i18, i18$State), envir=.GlobalEnv)

d <- subset(onset18, State == "Adamawa")
i <- incidence(as.Date(d$date_of_onset))
t_start <- seq(2, nrow(i$count)-29) 
t_end <- t_start + 29
i <- data.frame(i$dates, i$counts)
names(i)[1]<-paste("date")
names(i)[2]<-paste("count")
Rt <- estimate_Rt(i, estimation_family='epiestim', cumulative=TRUE, method = 'parametric_si', 
                  config = list(mean_si=mu2, std_si=sd, t_start = t_start, t_end = t_end))# change based on si
names(Adamawa)[2]<-paste("date_start")
Adamawa <- merge(Adamawa, Rt, by = "date_start", all = TRUE)

list2env(split(i18, i18$State), envir=.GlobalEnv)
# "Adamawa" "Bauchi"  "Borno"   "Gombe"   "Katsina" "Yobe"   
# "Adamawa" "Borno" 

`````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````

## COVARIATE SELECTION 
# Covariate selection is based on variable importance and correlation clustering 

# Correlation clustering 
# Read in data 
data1 <- read.csv("df1.csv") # file: "Hierarchical Regression + Random Forests/Data"
data1 <- data1[-c(1:3)]
data1 <- na.omit(data1)

corr1 <- hclust(dist(1-abs(cor(data1[-c(1)]))), method = 'average')
clusters <- cutree(hclust(dist(1-abs(cor(data1[-c(1)])))), k = 9)
rect.hclust(corr1, k = 9)
clusters2 <- data.frame(corr1[["labels"]], clusters)
clusters2 <- cutree(hclust(dist(1-abs(cor(data1[-c(1)])))), h = 0.25)

## Variable importance
set.seed(123)
split <- initial_split(data1, prop = .7)
train <- training(split)
test  <- testing(split)

OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {
  
  optimal_ranger <- ranger(
    formula         = Rt5 ~ ., 
    data            = train, 
    num.trees       = 500,
    mtry            = 2,
    min.node.size   = 5,
    sample.fraction = .7,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

var_importance <- data.frame(optimal_ranger$variable.importance)
var_importance <- rownames_to_column(var_importance, "variable")
names(var_importance)[2]<-paste("x")

`````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````

## RANDOM FOREST

# Find optimum parameters 
# Optimum ntree 
tunegrid <- expand.grid(.mtry = c(sqrt(ncol(train))))
modellist <- list()

for (ntree in c(500,1000,1500,2000,2500)){
  set.seed(123)
  fit <- train(Rt5~.,
               data = train,
               method = 'rf',
               metric = 'RMSE',
               tuneGrid = tunegrid,
               trControl = control,
               ntree = ntree)
  key <- toString(ntree)
  modellist[[key]] <- fit
}

results <- resamples(modellist)
summary(results)

# Optimum mtry 
control2 <- trainControl(method="boot", number=100)
boot <- train(Rt5 ~ ., data=train, trControl=control2, method="rf")
print(boot)

# Fit best-fit model 
# Stepping through model possibilities, shown was the best fit accroding to RMSE, R2 and correlations 
control <- trainControl(method='repeatedcv', 
                        number=10, 
                        repeats=5,
                        returnResamp = "final",
                        savePredictions = "final",
                        allowParallel = FALSE)
best_fit <- train(Rt5 ~ Sanitation + MPI + PDSI + monthly_conf, 
            data=train, 
            method='rf', 
            metric= "RMSE", 
            trControl=control)

# Test the model against the performance metrics 
pred_bestfit <- predict(best_fit, test)
# RMSE and R2
postResample(pred = pred_bestfit, obs = test$Rt5)
# MAE
mae <- mean(abs(predict(best_fit, test) - test$Rt5))
# Correlation 
cor(test$Rt5, pred_bestfit)

`````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````

## NOWCASTING 

# Read in my 31 state R has not been calculated for  
filename <- "predictions_df6.xlsx"
read_excel_allsheets <- function(filename, tibble = FALSE) {
  sheets <- readxl::excel_sheets(filename)
  x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
  if(!tibble) x <- lapply(x, as.data.frame)
  names(x) <- sheets
  x
}

adm_list <- read_excel_allsheets("predictions_df6.xlsx")
adm_data <- c("Abia","Akwa_Ibom","Anambra","Bayelsa","Benue","Cross River","Delta","Ebonyi",
              "Edo","Ekiti","Enugu","FCT","Imo","Jigawa","Kaduna","Kano","Kebbi","Kogi",
              "Kwara","Lagos","Nasarawa","Niger","Ogun","Ondo","Osun","Oyo","Plateau",
              "Rivers","Sokoto","Taraba","Zamfara")
              
# Save my dates to identify data points later 
full_dates$YearMon <- as.yearmon(paste(full_dates$year, full_dates$month), "%Y %m")

# Create predictions using the best fit model for each state with CI  
state_R_preds <- function(adm_data) {
  preds <- predict(best_fit, data.frame(monthly_conf=adm_data$monthly_conf, 
                                        PDSI=adm_data$PDSI, 
                                        Sanitation=adm_data$Sanitation, 
                                        MPI=adm_data$MPI), 
                   interval = 'confidence')
}

output_list <- lapply(adm_list, state_R_preds)

# Add dates to the predictions 
add_dates <- function(adm_data) {
  adm_data <- cbind(adm_data, full_dates)
}

output_list <- lapply(output_list, add_dates)

output_list <- lapply(output_list, function(x) { x["Date"] <- NULL; x })
output_list <- lapply(output_list, function(x) { x["year"] <- NULL; x })
output_list <- lapply(output_list, function(x) { x["month"] <- NULL; x })

# Format the predictions to save 
remove_duplicates2 <- function(adm_data) {
  adm_data <- adm_data %>% group_by(YearMon) %>%
    mutate(fit2 = mean(fit))
  adm_data <- adm_data %>% group_by(YearMon) %>%
    mutate(lwr2 = mean(lwr))
  adm_data <- adm_data %>% group_by(YearMon) %>%
    mutate(upr2 = mean(upr))
}

output_list <- lapply(output_list, remove_duplicates2)

output_list <- lapply(output_list, function(x) { x["fit"] <- NULL; x })
output_list <- lapply(output_list, function(x) { x["upr"] <- NULL; x })
output_list <- lapply(output_list, function(x) { x["lwr"] <- NULL; x })

remove_duplicates <- function(adm_data) {
  adm_data <- adm_data %>% distinct()
}

output_list <- lapply(output_list, remove_duplicates)

write.xlsx(output_list, file = "R_preds_by_state.xlsx")

`````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````

## TRAFFIC-LIGHT SYSTEM  

# Find the histroical averages spatially and temporally 
# Read in all my data for the 31 states 
filename <- "hist_exp_periods.xlsx"
read_excel_allsheets <- function(filename, tibble = FALSE) {
  sheets <- readxl::excel_sheets(filename)
  x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
  if(!tibble) x <- lapply(x, as.data.frame)
  names(x) <- sheets
  x
}
list1 <- read_excel_allsheets(filname)
df1 <- ldply(list1, data.frame)
df1$.id <- NULL

## Create a new column for the threshold 
df1 <- df1 %>% mutate(R_threshold = case_when(
  R >= 1 ~ "R >= 1", 
  R <= 1 ~ "R <= 1"
))

## Subset my data based on the thresholds 
df2 <- subset(df1, R_threshold == "R >= 1") 
df3 <- subset(df1, R_threshold == "R <= 1") 

## Get summary stats 
covariates <- c("Sanitation", "MPI", "monthly_conf", "PDSI")
list2 <- list(df2$Sanitation, df2$MPI, df2$monthly_conf, df2$PDSI)
names(list2) <- covariates
list3 <- list(df3$Sanitation, df3$MPI, df3$monthly_conf, df3$PDSI)
names(list3) <- covariates

stats_fun <- function(covariates) {
  stats <- describe(covariates)
}

output_over_1 <- lapply(list2, stats_fun)
output_under_1 <- lapply(list3, stats_fun)
output_over_1 <- ldply(output_over_1, data.frame)
output_under_1 <- ldply(output_under_1, data.frame)

output_over_1$R_threshold <- "R >= 1"
output_under_1$R_threshold <- "R <= 1"
output <- rbind(output_over_1, output_under_1)
output <- output[c(1,3,4,5,6,9,10,11,14,15)]
names(output)[1]<-paste("Variable")

## Spatially - By state
covariates <- c("Sanitation", "MPI", "monthly_conf", "PDSI")
list2 <- list(data.frame(df2$state, df2$Sanitation), data.frame(df2$state, df2$MPI), 
              data.frame(df2$state, df2$monthly_conf), data.frame(df2$state, df2$PDSI))
colnames <- c("State", "Variable")
list2 <- lapply(list2, setNames, colnames)
names(list2) <- covariates

list3 <- list(data.frame(df3$state, df3$Sanitation), data.frame(df3$state, df3$MPI), 
              data.frame(df3$state, df3$monthly_conf), data.frame(df3$state, df3$PDSI))
list3 <- lapply(list3, setNames, colnames)
names(list3) <- covariates

stats_fun_by_state <- function(covariates) {
  stats <- describe(Variable~State, data = covariates)
}
output_over_1_1 <- lapply(list2, stats_fun_by_state)
output_under_1_1 <- lapply(list3, stats_fun_by_state)

fun2 <- function(covariates) {
  do.call("rbind",covariates)
  rownames_to_column(covariates, "State")
}

output_over_1_1 <- lapply(output_over_1_1, fun2)
output_over_1_1 <- ldply(output_over_1_1, data.frame)
output_over_1_1 <- output_over_1_1[c(1,2,4,5,6,7,10,11,12,15)]
output_over_1_1$R_threshold <- "R >= 1"
names(output_over_1_1)[1]<-paste("Variable")

output_under_1_1 <- lapply(output_under_1_1, fun2)
output_under_1_1 <- ldply(output_under_1_1, data.frame)
output_under_1_1 <- output_under_1_1[c(1,2,4,5,6,7,10,11,12,15)]
output_under_1_1$R_threshold <- "R <= 1"
names(output_under_1_1)[1]<-paste("Variable")

## Temporally - By date 
list2 <- list(data.frame(df2$Date, df2$Sanitation), data.frame(df2$Date, df2$MPI), 
              data.frame(df2$Date, df2$monthly_conf), data.frame(df2$Date, df2$PDSI))
colnames <- c("Date", "Variable")
list2 <- lapply(list2, setNames, colnames)
names(list2) <- covariates

list3 <- list(data.frame(df3$Date, df3$Sanitation), data.frame(df3$Date, df3$MPI), 
              data.frame(df3$Date, df3$monthly_conf), data.frame(df3$Date, df3$PDSI))
list3 <- lapply(list3, setNames, colnames)
names(list3) <- covariates

stats_fun_by_date <- function(covariates) {
  stats <- describe(Variable~Date, data = covariates)
}
output_over_1_2 <- lapply(list2, stats_fun_by_date)
output_under_1_2 <- lapply(list3, stats_fun_by_date)

fun2 <- function(covariates) {
  do.call("rbind",covariates)
}

fun3 <- function(covariates) {
  rownames_to_column(covariates, "Date")
}

output_over_1_2 <- lapply(output_over_1_2, fun2)
output_over_1_2 <- lapply(output_over_1_2, fun3)
output_over_1_2 <- ldply(output_over_1_2, data.frame)
output_over_1_2 <- output_over_1_2[c(1,2,4,5,6,7,10,11,12,15)]
output_over_1_2$R_threshold <- "R >= 1"
names(output_over_1_2)[1]<-paste("Variable")

output_under_1_2 <- lapply(output_under_1_2, fun2)
output_under_1_2 <- lapply(output_under_1_2, fun3)
output_under_1_2 <- ldply(output_under_1_2, data.frame)
output_under_1_2 <- output_under_1_2[c(1,2,4,5,6,7,10,11,12,15)]
output_under_1_2$R_threshold <- "R <= 1"
names(output_under_1_2)[1]<-paste("Variable")

# Taken standard error and mean and used this to create the traffic-light 
sanitation_red <- seq(48.9, 50, length.out = 15)
sanitation_green <- seq(67.3, 68.7, length.out = 15)
sanitation_amber <- (((sanitation_green-sanitation_red)/2)+sanitation_red)

mpi_red <- seq(0.27, 0.29, length.out = 15)
mpi_green <- seq(0.08, 0.1, length.out = 15)
mpi_amber <- (((mpi_red-mpi_green)/2)+mpi_green)

pdsi_red <- seq(-0.5, -0.34, length.out = 15)
pdsi_green <- seq(-1.66, -1.44, length.out = 15)
pdsi_amber <- (((pdsi_red-pdsi_green)/2)+pdsi_green)

conflict_red <- seq(2.21, 2.8, length.out = 15)
conflict_green <- seq(3.7, 4.31, length.out = 15)
conflict_amber <- (((conflict_green-conflict_red)/2)+conflict_red)

preds_green <- predict(best_fit, data.frame(monthly_conf=conflict_green, 
                                            PDSI=pdsi_green, 
                                            Sanitation=sanitation_green, 
                                            MPI=mpi_green))
                                            
                                            
preds_amber <- predict(best_fit, data.frame(monthly_conf=conflict_amber, 
                                            PDSI=pdsi_amber, 
                                            Sanitation=sanitation_amber, 
                                            MPI=mpi_amber))

preds_red <- predict(best_fit, data.frame(monthly_conf=conflict_red, 
                                          PDSI=pdsi_red, 
                                          Sanitation=sanitation_red, 
                                          MPI=mpi_red))
numbers <- seq(1,15,1)

preds <- data.frame(numbers, preds_red, preds_amber, preds_green)
preds <- preds %>% gather(Light, Prediction, 2:4)
preds$Light[preds$Light == "preds_red"] <- "Red"
preds$Light[preds$Light == "preds_amber"] <- "Amber"
preds$Light[preds$Light == "preds_green"] <- "Green"

preds$Light <- factor(preds$Light, levels = c("Red", "Amber", "Green"))

## Compare them all again 
conflict <- data.frame(numbers, conflict_red, conflict_amber, conflict_green)
mpi <- data.frame(numbers, mpi_red, mpi_amber, mpi_green)
sanitation <- data.frame(numbers, sanitation_red, sanitation_amber, sanitation_green)
pdsi <- data.frame(numbers, pdsi_red, pdsi_amber, pdsi_green)

conflict <- conflict %>% gather(Light, Prediction, 2:4)
mpi <- mpi %>% gather(Light, Prediction, 2:4)
sanitation <- sanitation %>% gather(Light, Prediction, 2:4)
pdsi <- pdsi %>% gather(Light, Prediction, 2:4)
# There was some manipulaton of these to understand the relationships and tweak the covaraites around R = 1 










